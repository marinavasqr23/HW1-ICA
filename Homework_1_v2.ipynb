{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marinavasqr23/HW1-ICA/blob/main/Homework_1_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANÁLISE DE DADOS DATASET \"WHINE QUALITY\""
      ],
      "metadata": {
        "id": "TB2cakZsT17J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. IMPORTANDO BIBLIOTECAS"
      ],
      "metadata": {
        "id": "I5O4v5f3VqXj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k_Zyyv3T0aM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOlHHnwpUy19",
        "outputId": "b12e1166-485c-4b47-c0fc-41204a388f52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. TRATANDO OS DADOS"
      ],
      "metadata": {
        "id": "ytuJH4L1T-d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Verify the contents of the directory\n",
        "!ls \"/content/drive/MyDrive/Homework/\"\n",
        "\n",
        "# Load the datasets\n",
        "dt_whine_red = pd.read_csv(\"/content/drive/MyDrive/Homework/winequality-red.csv\", sep=\";\")\n",
        "dt_whine_white = pd.read_csv(\"/content/drive/MyDrive/Homework/winequality-white.csv\", sep=\";\")"
      ],
      "metadata": {
        "id": "xeHZkGjdUNRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_whine_red.info()"
      ],
      "metadata": {
        "id": "CzjLcdfNVMec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_whine_white.info()"
      ],
      "metadata": {
        "id": "5vUhY9vnVjrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFERINDO INCONSISTÊNCIA ENTRE OS VALORES PARA PADRONIZAR OS TIPOS\n",
        "# Tudo OK\n",
        "dt_whine_white['alcohol'].unique()"
      ],
      "metadata": {
        "id": "mrzIrs7OaaTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFERINDO INCONSISTÊNCIA ENTRE OS VALORES PARA PADRONIZAR OS TIPOS\n",
        "# Observe que alguns valores estranhos e por isso a coluna está como Object\n",
        "dt_whine_red['alcohol'].unique()"
      ],
      "metadata": {
        "id": "ZkLvAP7bZxiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista com os valores a serem corrigidos e suas substituições\n",
        "dict_whine_red = {\n",
        "    '100.333.333.333.333': '100',\n",
        "    '110.666.666.666.667': '110',\n",
        "    '956.666.666.666.667': '956',\n",
        "    '135.666.666.666.667': '135',\n",
        "    '923.333.333.333.333': '923'\n",
        "}"
      ],
      "metadata": {
        "id": "2Ru-Xay4ayrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Substituindo os valores\n",
        "dt_whine_red['alcohol'] = dt_whine_red['alcohol'].replace(dict_whine_red)"
      ],
      "metadata": {
        "id": "dBsccn6ZbaoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Valores substituídos\n",
        "dt_whine_red['alcohol'].unique()"
      ],
      "metadata": {
        "id": "o8Xap-LDfRnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alterando para numeric\n",
        "dt_whine_red['alcohol'] = pd.to_numeric(dt_whine_red['alcohol'])"
      ],
      "metadata": {
        "id": "wvywb4yRf5d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividindo os  valores substituídos\n",
        "dt_whine_red['alcohol'] = np.where(\n",
        "    dt_whine_red['alcohol'] >= 100,\n",
        "    dt_whine_red['alcohol'] / 100,\n",
        "    dt_whine_red['alcohol']\n",
        ")"
      ],
      "metadata": {
        "id": "euKMsB4ofeEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_whine_red['alcohol'].unique()"
      ],
      "metadata": {
        "id": "mBpMdxrmglIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_whine_red.info()"
      ],
      "metadata": {
        "id": "woGnTYzogwtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazemos um concatenção da tabelas\n",
        "dt_whine_all = pd.concat([dt_whine_red, dt_whine_white], ignore_index=True)"
      ],
      "metadata": {
        "id": "3CgmcOsfh--s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisando nosso dataset percebemos uma discrepancia entre o minimo e maximo da densidade\n",
        "dt_whine_all.describe()"
      ],
      "metadata": {
        "id": "7crArAS38kUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisando valores maiores que média da densidade, observamos que temos 4 linhas com valores muito discrepantes\n",
        "bigger_than_one = dt_whine_red[dt_whine_red['density'] > 1]['density']\n",
        "print(\"Valores > 1:\")\n",
        "print(bigger_than_one.head())"
      ],
      "metadata": {
        "id": "k6Fc5b1I-JsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_whine_red['density'] = np.where (\n",
        "    dt_whine_red['density'] > 1,\n",
        "    dt_whine_red['density'] > 100,\n",
        "    dt_whine_red['density']\n",
        ")"
      ],
      "metadata": {
        "id": "3q4kWgiV-ku2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. ANÁLISE UNIVARIADA INCONDICIONAL"
      ],
      "metadata": {
        "id": "2szRPi37jjM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.1. Histograma dos Preditores"
      ],
      "metadata": {
        "id": "3EtK5_4_2F9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def univariate_statistics_histogram_frequency(dataset):\n",
        "    predictors_columns = dataset.columns[:11]\n",
        "\n",
        "    fig, axs = plt.subplots(4, 3, figsize=(10, 12))\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    colors = ['#FFB6C1', '#87CEFA', '#98FB98', '#DDA0DD', '#FFFACD','#F0E68C', '#E6E6FA', '#F5DEB3', '#B0E0E6', '#FFDAB9', '#DA70D6']\n",
        "\n",
        "    for i, column in enumerate(predictors_columns):\n",
        "        data = dataset[column]\n",
        "\n",
        "        axs[i].hist(data, bins=20, color=colors[i], edgecolor='black', alpha=0.7)\n",
        "        axs[i].set_title(f\"{column.title()}\")\n",
        "        axs[i].set_xlabel(column.title())\n",
        "        axs[i].set_ylabel(\"Frequência\")\n",
        "        axs[i].grid(True, alpha=0.3)\n",
        "\n",
        "    for i in range(len(predictors_columns), len(axs)):\n",
        "        axs[i].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "univariate_statistics_histogram_frequency(dt_whine_red)"
      ],
      "metadata": {
        "id": "C24Zb5Ebx9Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2. Calculando os valores da Média, Desvio Padrão e Assimetria de cada preditor"
      ],
      "metadata": {
        "id": "sbMglmYNxnrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def univariate_statistics_values(dt_whine_all):\n",
        "    values = []\n",
        "    predictors_columns = dt_whine_all.columns[:11]\n",
        "\n",
        "    for column in predictors_columns:\n",
        "        mean = dt_whine_all[column].mean() # Média\n",
        "        std_dev = dt_whine_all[column].std() # Desvio padrão\n",
        "        skewness = dt_whine_all[column].skew() # Assimetria\n",
        "\n",
        "        values.append({\n",
        "            \"Preditor\": column,\n",
        "            \"Média (µ)\": round(mean, 4),\n",
        "            \"Desvio Padrão (σ)\": round(std_dev, 4),\n",
        "            \"Assimetria (γ)\": round(skewness, 4)\n",
        "        })\n",
        "\n",
        "    results = pd.DataFrame(values)\n",
        "    return results\n",
        "\n",
        "table_statistics = univariate_statistics_values(dt_whine_all)\n",
        "print(table_statistics.to_string(index=False))"
      ],
      "metadata": {
        "id": "HWvEbE4SssxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ghKQcVz9BsEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Análise Bivariada Incondicional"
      ],
      "metadata": {
        "id": "LRIcy-CdKnAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def bivariate_statistics_scatter(dataset):\n",
        "    predictors_columns = dataset.columns[:11]  # seleciona os 11 preditores numéricos\n",
        "    num_pairs = len(predictors_columns)\n",
        "\n",
        "    # Gera pares de variáveis (só combinações únicas)\n",
        "    pairs = [(predictors_columns[i], predictors_columns[j])\n",
        "             for i in range(num_pairs) for j in range(i + 1, num_pairs)]\n",
        "\n",
        "    # Seleciona até 12 pares para visualizar (para não ficar enorme)\n",
        "    pairs = pairs[:12]\n",
        "\n",
        "    fig, axs = plt.subplots(4, 3, figsize=(12, 12))\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    colors = ['#FFB6C1', '#87CEFA', '#98FB98', '#DDA0DD', '#FFFACD',\n",
        "              '#F0E68C', '#E6E6FA', '#F5DEB3', '#B0E0E6', '#FFDAB9', '#DA70D6', '#FFC0CB', '#B0C4DE']\n",
        "\n",
        "    for i, (x, y) in enumerate(pairs):\n",
        "        sns.scatterplot(data=dataset, x=x, y=y, alpha=0.5, color=colors[i], edgecolor=None, ax=axs[i])\n",
        "        axs[i].set_title(f\"{x.title()} vs {y.title()}\", fontsize=10)\n",
        "        axs[i].set_xlabel(x.title())\n",
        "        axs[i].set_ylabel(y.title())\n",
        "        axs[i].grid(True, alpha=0.3)\n",
        "\n",
        "    for i in range(len(pairs), len(axs)):\n",
        "        axs[i].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Exemplo de uso:\n",
        "bivariate_statistics_scatter(dt_whine_all)"
      ],
      "metadata": {
        "id": "ubP3grShLSfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Análise Multivariada Incondicional"
      ],
      "metadata": {
        "id": "JnC96TpBsO-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement PCA from scratch, attempt to load referenced winequality files if present; otherwise fall back to Iris dataset.\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Helper: manual PCA implementation\n",
        "def manual_pca(X, n_components=2, standardize=True):\n",
        "    # X: numpy array (n_samples, n_features)\n",
        "    if standardize:\n",
        "        mean = np.mean(X, axis=0)\n",
        "        std = np.std(X, axis=0, ddof=1)\n",
        "        std_repl = std.copy()\n",
        "        std_repl[std_repl == 0] = 1.0\n",
        "        Xs = (X - mean) / std_repl\n",
        "    else:\n",
        "        Xs = X - np.mean(X, axis=0)\n",
        "    # Covariance matrix (features x features)\n",
        "    cov = np.cov(Xs, rowvar=False, ddof=1)\n",
        "    # Eigen decomposition\n",
        "    eigvals, eigvecs = np.linalg.eigh(cov)  # eigh for symmetric\n",
        "    # Sort eigenvalues descending\n",
        "    idx = np.argsort(eigvals)[::-1]\n",
        "    eigvals = eigvals[idx]\n",
        "    eigvecs = eigvecs[:, idx]\n",
        "    # Select top components\n",
        "    components = eigvecs[:, :n_components]\n",
        "    # Project data\n",
        "    projected = Xs.dot(components)\n",
        "    # Explained variance ratio\n",
        "    explained_variance_ratio = eigvals / np.sum(eigvals)\n",
        "    return {\n",
        "        \"mean\": mean,\n",
        "        \"std\": std_repl if standardize else None,\n",
        "        \"components\": components,\n",
        "        \"eigvals\": eigvals,\n",
        "        \"explained_variance_ratio\": explained_variance_ratio,\n",
        "        \"projected\": projected\n",
        "    }\n",
        "\n",
        "# Try to load winequality datasets referenced in the uploaded script\n",
        "paths = [\n",
        "    \"/content/drive/MyDrive/Homework/winequality-red.csv\",\n",
        "    \"/content/drive/MyDrive/Homework/winequality-white.csv\",\n",
        "    \"/mnt/data/winequality-red.csv\",\n",
        "    \"/mnt/data/winequality-white.csv\",\n",
        "    \"./winequality-red.csv\",\n",
        "    \"./winequality-white.csv\"\n",
        "]\n",
        "wine_files = [p for p in paths if os.path.exists(p)]\n",
        "data_used = None\n",
        "\n",
        "if len(wine_files) >= 2:\n",
        "    red = pd.read_csv(wine_files[0], sep=\";\")\n",
        "    white = pd.read_csv(wine_files[1], sep=\";\")\n",
        "    df = pd.concat([red, white], ignore_index=True)\n",
        "    # create class label if not present: use 'quality' as class (binned)\n",
        "    if 'quality' in df.columns:\n",
        "        labels = df['quality'].astype(str).values\n",
        "    else:\n",
        "        labels = np.zeros(len(df), dtype=str)\n",
        "    X = df.select_dtypes(include=[np.number]).values\n",
        "    data_used = \"wine (from local files)\"\n",
        "else:\n",
        "    # Fall back to iris dataset\n",
        "    try:\n",
        "        from sklearn import datasets\n",
        "        iris = datasets.load_iris()\n",
        "        X = iris.data\n",
        "        labels = iris.target\n",
        "        target_names = iris.target_names\n",
        "        data_used = \"iris (sklearn)\"\n",
        "    except Exception as e:\n",
        "        # If sklearn not available, create synthetic dataset\n",
        "        rng = np.random.RandomState(0)\n",
        "        X = np.vstack([rng.normal(loc=-2, scale=1, size=(50,4)),\n",
        "                       rng.normal(loc=2, scale=1, size=(50,4)),\n",
        "                       rng.normal(loc=5, scale=1, size=(50,4))])\n",
        "        labels = np.array([0]*50 + [1]*50 + [2]*50)\n",
        "        target_names = np.array([\"class0\",\"class1\",\"class2\"])\n",
        "        data_used = \"synthetic\"\n",
        "\n",
        "# Run PCA\n",
        "result = manual_pca(X, n_components=2, standardize=True)\n",
        "proj = result[\"projected\"]\n",
        "explained = result[\"explained_variance_ratio\"]\n",
        "\n",
        "# Plotting scatter with class labels as different markers/colors\n",
        "unique_labels, inv = np.unique(labels, return_inverse=True)\n",
        "markers = ['o', 's', '^', 'D', 'v', 'P', 'X']  # cycle markers\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, lab in enumerate(unique_labels):\n",
        "    mask = (inv == i)\n",
        "    plt.scatter(proj[mask,0], proj[mask,1], label=str(lab), marker=markers[i % len(markers)], edgecolor='k', linewidth=0.4, s=60)\n",
        "plt.xlabel(\"PC1 (%.2f%% variance)\" % (explained[0]*100))\n",
        "plt.ylabel(\"PC2 (%.2f%% variance)\" % (explained[1]*100))\n",
        "plt.title(\"PCA projection onto first two principal components — %s\" % data_used)\n",
        "plt.legend(title=\"Class\", bbox_to_anchor=(1.05,1), loc='upper left')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary (explained variance ratios)\n",
        "print(\"Data used:\", data_used)\n",
        "print(\"Explained variance ratios (top 5):\", np.round(explained[:5], 4))\n",
        "print(\"Eigenvalues (top 5):\", np.round(result['eigvals'][:5], 4))\n"
      ],
      "metadata": {
        "id": "UeiP8GXVkwRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zjC9INNgsaAp"
      }
    }
  ]
}